# ğŸ‰ CLI/API åŒæ¨¡å¼æ”¹é€ å®Œæˆæ€»ç»“

## ğŸ“¦ æ”¹é€ å†…å®¹æ¦‚è§ˆ

ä½ çš„ thumb2original é¡¹ç›®å·²æˆåŠŸæ”¹é€ ä¸ºæ”¯æŒ **CLI** å’Œ **API æœåŠ¡å™¨** åŒæ¨¡å¼è¿è¡Œçš„æ¶æ„ï¼

---

## âœ¨ æ–°å¢åŠŸèƒ½

### 1. **API æœåŠ¡å™¨æ¨¡å¼**
- âœ… RESTful API æ¥å£
- âœ… WebSocket å®æ—¶è¿›åº¦æ¨é€
- âœ… ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
- âœ… å¹¶å‘æ§åˆ¶
- âœ… è¿œç¨‹è®¿é—®èƒ½åŠ›

### 2. **æ ¸å¿ƒå¼•æ“æŠ½è±¡**
- âœ… `ScraperEngine` - CLI å’Œ API å…±äº«çš„æ ¸å¿ƒé€»è¾‘
- âœ… äº‹ä»¶é©±åŠ¨æ¶æ„
- âœ… çŠ¶æ€ç®¡ç†
- âœ… è¿›åº¦å›è°ƒ

### 3. **ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ**
- âœ… `TaskManager` - ä»»åŠ¡é˜Ÿåˆ—å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†
- âœ… è‡ªåŠ¨è°ƒåº¦
- âœ… ä»»åŠ¡ç»Ÿè®¡
- âœ… æ¸…ç†æœºåˆ¶

---

## ğŸ“ æ–°å¢æ–‡ä»¶åˆ—è¡¨

```
thumb2original/
â”œâ”€â”€ lib/core/
â”‚   â””â”€â”€ ScraperEngine.js          # æ ¸å¿ƒçˆ¬è™«å¼•æ“ï¼ˆ342 è¡Œï¼‰
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ index.js                  # API æœåŠ¡å™¨ï¼ˆ370 è¡Œï¼‰
â”‚   â””â”€â”€ TaskManager.js            # ä»»åŠ¡ç®¡ç†å™¨ï¼ˆ230 è¡Œï¼‰
â”‚
â”œâ”€â”€ cli.js                        # CLI æ¨¡å¼å…¥å£ï¼ˆ72 è¡Œï¼‰
â”œâ”€â”€ server.js                     # æœåŠ¡å™¨æ¨¡å¼å…¥å£ï¼ˆ42 è¡Œï¼‰
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ api-client.html           # Web å®¢æˆ·ç«¯ç¤ºä¾‹ï¼ˆ680 è¡Œï¼‰
â”‚   â””â”€â”€ node-client.js            # Node.js å®¢æˆ·ç«¯ç¤ºä¾‹ï¼ˆ280 è¡Œï¼‰
â”‚
â””â”€â”€ æ–‡æ¡£/
    â”œâ”€â”€ API_GUIDE.md              # API å®Œæ•´ä½¿ç”¨æŒ‡å—
    â”œâ”€â”€ MIGRATION_GUIDE.md        # è¿ç§»æŒ‡å—
    â”œâ”€â”€ ARCHITECTURE.md           # æ¶æ„è®¾è®¡æ–‡æ¡£
    â””â”€â”€ DUAL_MODE_SUMMARY.md      # æœ¬æ–‡ä»¶
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…æ–°ä¾èµ–

```bash
npm install express cors socket.io
```

### CLI æ¨¡å¼ï¼ˆåŸæœ‰æ–¹å¼ï¼‰

```bash
# åŸæœ‰æ–¹å¼ä»å¯ç”¨
npm start
node index.js

# æ¨èä½¿ç”¨æ–°å…¥å£
npm run cli
node cli.js
```

### API æœåŠ¡å™¨æ¨¡å¼ï¼ˆæ–°å¢ï¼‰

```bash
# å¯åŠ¨æœåŠ¡å™¨
npm run server

# å¼€å‘æ¨¡å¼ï¼ˆè‡ªåŠ¨é‡å¯ï¼‰
npm run dev

# è‡ªå®šä¹‰ç«¯å£
PORT=8080 npm run server
```

### è®¿é—® Web å®¢æˆ·ç«¯

å¯åŠ¨æœåŠ¡å™¨åï¼Œåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼š
```
file:///path/to/thumb2original/examples/api-client.html
```

---

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: CLI æ¨¡å¼ï¼ˆä¿æŒä¸å˜ï¼‰

```bash
# ç¼–è¾‘ config/config.js é…ç½®ä½ çš„çˆ¬å–å‚æ•°
node cli.js
```

### ç¤ºä¾‹ 2: API æ¨¡å¼ - ä½¿ç”¨ cURL

```bash
# åˆ›å»ºä»»åŠ¡
curl -X POST http://localhost:3000/api/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "config": {
      "scrapeMode": "single_page",
      "imageMode": "originals_only",
      "targetUrl": "https://example.com/gallery"
    }
  }'

# å“åº”: { "taskId": "task_xxx", "status": "created" }

# æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
curl http://localhost:3000/api/tasks/task_xxx

# æŸ¥çœ‹æ‰€æœ‰ä»»åŠ¡
curl http://localhost:3000/api/tasks

# å–æ¶ˆä»»åŠ¡
curl -X POST http://localhost:3000/api/tasks/task_xxx/cancel
```

### ç¤ºä¾‹ 3: API æ¨¡å¼ - ä½¿ç”¨ Node.js

```javascript
import fetch from 'node-fetch'

// åˆ›å»ºä»»åŠ¡
const response = await fetch('http://localhost:3000/api/tasks', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    config: {
      scrapeMode: 'single_page',
      imageMode: 'originals_only',
      targetUrl: 'https://example.com/gallery'
    }
  })
})

const { taskId } = await response.json()
console.log('ä»»åŠ¡ID:', taskId)

// è½®è¯¢ä»»åŠ¡çŠ¶æ€
setInterval(async () => {
  const statusRes = await fetch(`http://localhost:3000/api/tasks/${taskId}`)
  const task = await statusRes.json()
  console.log('çŠ¶æ€:', task.status)

  if (task.status === 'completed') {
    console.log('å®Œæˆï¼', task.result)
    process.exit(0)
  }
}, 2000)
```

### ç¤ºä¾‹ 4: ä½¿ç”¨ WebSocket å®æ—¶ç›‘æ§

```javascript
import { io } from 'socket.io-client'

const socket = io('http://localhost:3000')

// è®¢é˜…æ‰€æœ‰ä»»åŠ¡
socket.emit('subscribe')

// ç›‘å¬è¿›åº¦
socket.on('task:progress', (data) => {
  console.log('è¿›åº¦:', data.progress)
})

socket.on('task:completed', (data) => {
  console.log('ä»»åŠ¡å®Œæˆ:', data.result)
})
```

### ç¤ºä¾‹ 5: ä½œä¸ºåº“ä½¿ç”¨

```javascript
import { ScraperEngine } from './lib/core/ScraperEngine.js'

const engine = new ScraperEngine({
  scrapeMode: 'single_page',
  targetUrl: 'https://example.com',
  imageMode: 'originals_only'
}, {
  onProgress: (progress) => {
    console.log('è¿›åº¦:', progress)
  },
  onComplete: (summary) => {
    console.log('å®Œæˆ:', summary)
  }
})

await engine.run()
```

---

## ğŸ“Š æ¶æ„å¯¹æ¯”

### æ”¹é€ å‰ï¼ˆçº¯ CLIï¼‰

```
ç”¨æˆ·
  â†“
index.js (å•å…¥å£)
  â†“
ç›´æ¥è°ƒç”¨ä¸šåŠ¡é€»è¾‘
  â†“
æµè§ˆå™¨ â†’ æŠ“å– â†’ ä¸‹è½½
```

### æ”¹é€ åï¼ˆåŒæ¨¡å¼ï¼‰

```
       ç”¨æˆ·
      /    \
   CLI      APIå®¢æˆ·ç«¯
    â†“          â†“
  cli.js   HTTP API
    \        /
  ScraperEngine (æ ¸å¿ƒå¼•æ“)
       â†“
  TaskManager (ä»»åŠ¡ç®¡ç†)
       â†“
   ä¸šåŠ¡é€»è¾‘å±‚
       â†“
  æµè§ˆå™¨ â†’ æŠ“å– â†’ ä¸‹è½½
```

---

## ğŸ”‘ æ ¸å¿ƒè®¾è®¡ç†å¿µ

### 1. **å…³æ³¨ç‚¹åˆ†ç¦»**
- CLI æ¨¡å¼ï¼š`cli.js` â†’ å‘½ä»¤è¡Œäº¤äº’
- API æ¨¡å¼ï¼š`server.js` â†’ HTTP/WebSocket æœåŠ¡
- æ ¸å¿ƒé€»è¾‘ï¼š`ScraperEngine` â†’ çˆ¬è™«ä¸šåŠ¡ï¼ˆå…±äº«ï¼‰

### 2. **äº‹ä»¶é©±åŠ¨**
- ä½¿ç”¨ Node.js EventEmitter
- è§£è€¦ä»»åŠ¡æ‰§è¡Œå’ŒçŠ¶æ€é€šçŸ¥
- æ”¯æŒå®æ—¶è¿›åº¦æ¨é€

### 3. **å‘åå…¼å®¹**
- ä¿ç•™ `index.js`ï¼Œä¸ç ´åç°æœ‰ç”¨æˆ·ä½¿ç”¨
- æ–°ç”¨æˆ·ä½¿ç”¨ `cli.js` å’Œ `server.js`
- æ¸è¿›å¼è¿ç§»

### 4. **æ‰©å±•æ€§**
- æ˜“äºæ·»åŠ æ–°çš„å­˜å‚¨åç«¯ï¼ˆRedis, MongoDBï¼‰
- æ˜“äºæ·»åŠ è®¤è¯ã€é™æµç­‰ä¸­é—´ä»¶
- æ˜“äºé›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

---

## ğŸ“¡ API æ¥å£é€Ÿè§ˆ

| æ–¹æ³• | è·¯å¾„ | è¯´æ˜ |
|------|------|------|
| GET | `/health` | å¥åº·æ£€æŸ¥ |
| POST | `/api/tasks` | åˆ›å»ºä»»åŠ¡ |
| GET | `/api/tasks` | è·å–æ‰€æœ‰ä»»åŠ¡ |
| GET | `/api/tasks/:id` | è·å–ä»»åŠ¡çŠ¶æ€ |
| POST | `/api/tasks/:id/cancel` | å–æ¶ˆä»»åŠ¡ |
| DELETE | `/api/tasks/:id` | åˆ é™¤ä»»åŠ¡ |
| POST | `/api/tasks/cleanup` | æ¸…ç†å·²å®Œæˆä»»åŠ¡ |
| GET | `/api/docs` | API æ–‡æ¡£ |

### WebSocket äº‹ä»¶

| äº‹ä»¶ | è¯´æ˜ |
|------|------|
| `task:created` | ä»»åŠ¡åˆ›å»º |
| `task:started` | ä»»åŠ¡å¼€å§‹ |
| `task:progress` | è¿›åº¦æ›´æ–° |
| `task:completed` | ä»»åŠ¡å®Œæˆ |
| `task:failed` | ä»»åŠ¡å¤±è´¥ |
| `task:cancelled` | ä»»åŠ¡å–æ¶ˆ |

---

## ğŸ¨ Web å®¢æˆ·ç«¯é¢„è§ˆ

æ‰“å¼€ `examples/api-client.html` å¯ä»¥çœ‹åˆ°ï¼š

- ğŸ“ ä»»åŠ¡åˆ›å»ºè¡¨å•
- ğŸ“Š å®æ—¶ç³»ç»Ÿç»Ÿè®¡
- ğŸ“‹ ä»»åŠ¡åˆ—è¡¨ï¼ˆå¸¦çŠ¶æ€å’Œè¿›åº¦æ¡ï¼‰
- ğŸ“¡ WebSocket å®æ—¶æ—¥å¿—
- âœ¨ ç°ä»£åŒ– UI è®¾è®¡

---

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰ï¼š

```env
# æœåŠ¡å™¨é…ç½®
PORT=3000
HOST=0.0.0.0
MAX_CONCURRENT=3
CORS_ORIGIN=*

# API è®¤è¯ï¼ˆå¯é€‰ï¼Œéœ€è¦è‡ªå·±å®ç°ä¸­é—´ä»¶ï¼‰
API_KEY=your-secret-key

# Redisï¼ˆå¦‚æœä½¿ç”¨æŒä¹…åŒ–ï¼‰
REDIS_URL=redis://localhost:6379
```

---

## ğŸ“ˆ æ€§èƒ½å’Œèµ„æºç®¡ç†

### å¹¶å‘æ§åˆ¶

```javascript
// æ ¹æ®æœåŠ¡å™¨èµ„æºè°ƒæ•´
const taskManager = new TaskManager({
  maxConcurrent: 5  // æœ€å¤šåŒæ—¶è¿è¡Œ 5 ä¸ªä»»åŠ¡
})
```

### è‡ªåŠ¨æ¸…ç†

```javascript
// å®šæœŸæ¸…ç† 1 å°æ—¶å‰çš„å·²å®Œæˆä»»åŠ¡
setInterval(() => {
  taskManager.cleanupCompletedTasks(3600000)
}, 600000) // æ¯ 10 åˆ†é’Ÿ
```

---

## ğŸ”’ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å»ºè®®

### 1. ä½¿ç”¨ PM2

```bash
npm install -g pm2

# å¯åŠ¨æœåŠ¡å™¨
pm2 start server.js --name thumb2original

# å¼€æœºè‡ªå¯
pm2 startup
pm2 save
```

### 2. ä½¿ç”¨ Nginx åå‘ä»£ç†

```nginx
server {
    listen 80;
    server_name api.yourdomain.com;

    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
    }
}
```

### 3. ä½¿ç”¨ Docker

```dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install --production
COPY . .
EXPOSE 3000
CMD ["node", "server.js"]
```

```bash
# æ„å»ºé•œåƒ
docker build -t thumb2original .

# è¿è¡Œå®¹å™¨
docker run -d -p 3000:3000 --name thumb2original-api thumb2original
```

---

## ğŸ§ª æµ‹è¯•å»ºè®®

### å•å…ƒæµ‹è¯•ï¼ˆScraperEngineï¼‰

```javascript
import { ScraperEngine } from './lib/core/ScraperEngine.js'
import { describe, it, expect } from 'vitest'

describe('ScraperEngine', () => {
  it('should create engine with config', () => {
    const engine = new ScraperEngine({ scrapeMode: 'single_page' })
    expect(engine.status).toBe('idle')
  })

  it('should emit progress events', async () => {
    let progressCalled = false
    const engine = new ScraperEngine(config, {
      onProgress: () => { progressCalled = true }
    })
    await engine.run()
    expect(progressCalled).toBe(true)
  })
})
```

### é›†æˆæµ‹è¯•ï¼ˆAPIï¼‰

```javascript
import { ScraperServer } from './server/index.js'
import fetch from 'node-fetch'

describe('API Server', () => {
  let server

  beforeAll(async () => {
    server = new ScraperServer({ port: 3001 })
    await server.start()
  })

  afterAll(async () => {
    await server.stop()
  })

  it('should create task', async () => {
    const res = await fetch('http://localhost:3001/api/tasks', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ config: { scrapeMode: 'single_page' } })
    })
    const data = await res.json()
    expect(data.taskId).toBeDefined()
  })
})
```

---

## ğŸš§ åç»­æ‰©å±•æ–¹å‘

### 1. æŒä¹…åŒ–å­˜å‚¨
- é›†æˆ Redis æˆ– MongoDB
- ä»»åŠ¡çŠ¶æ€æŒä¹…åŒ–
- æ”¯æŒæœåŠ¡å™¨é‡å¯åæ¢å¤ä»»åŠ¡

### 2. è®¤è¯å’Œæˆæƒ
- JWT è®¤è¯
- API Key ç®¡ç†
- ç”¨æˆ·æƒé™æ§åˆ¶

### 3. æ›´å¤šå®¢æˆ·ç«¯
- Python SDK
- Go SDK
- å®˜æ–¹ npm åŒ…

### 4. å¢å¼ºåŠŸèƒ½
- ä»»åŠ¡ä¼˜å…ˆçº§
- å®šæ—¶ä»»åŠ¡
- Webhook é€šçŸ¥
- é‚®ä»¶é€šçŸ¥

### 5. ç›‘æ§å’Œæ—¥å¿—
- Prometheus metrics
- ELK æ—¥å¿—èšåˆ
- æ€§èƒ½ç›‘æ§

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

| æ–‡æ¡£ | è¯´æ˜ |
|------|------|
| [API_GUIDE.md](./API_GUIDE.md) | API å®Œæ•´ä½¿ç”¨æŒ‡å— |
| [MIGRATION_GUIDE.md](./MIGRATION_GUIDE.md) | è¿ç§»å’Œå‡çº§æŒ‡å— |
| [ARCHITECTURE.md](./ARCHITECTURE.md) | è¯¦ç»†æ¶æ„è®¾è®¡æ–‡æ¡£ |
| [README.md](./README.md) | é¡¹ç›®åŸºç¡€è¯´æ˜ |
| [tests/TESTING_GUIDE.md](./tests/TESTING_GUIDE.md) | æµ‹è¯•æŒ‡å— |

---

## âœ… å…¼å®¹æ€§è¯´æ˜

### å‘åå…¼å®¹

âœ… **å®Œå…¨å…¼å®¹**ï¼šåŸæœ‰çš„ `npm start` å’Œ `node index.js` ä»å¯æ­£å¸¸ä½¿ç”¨

âœ… **é…ç½®å…¼å®¹**ï¼š`config/config.js` é…ç½®æ–‡ä»¶æ ¼å¼ä¸å˜

âœ… **API ç¨³å®š**ï¼š`lib/publicApi.js` å…¬å…±æ¥å£ä¿æŒä¸å˜

### æ–°åŠŸèƒ½

ğŸ†• **CLI æ¨¡å¼**ï¼šæ¨èä½¿ç”¨ `npm run cli` æˆ– `node cli.js`

ğŸ†• **API æ¨¡å¼**ï¼šä½¿ç”¨ `npm run server` å¯åŠ¨ HTTP API æœåŠ¡

ğŸ†• **ç¼–ç¨‹è°ƒç”¨**ï¼šå¯ä»¥é€šè¿‡ `ScraperEngine` ç±»åœ¨ä»£ç ä¸­è°ƒç”¨

---

## ğŸ é¢å¤–èµ„æº

### ç¤ºä¾‹ä»£ç 

- âœ… `examples/api-client.html` - å®Œæ•´çš„ Web ç®¡ç†ç•Œé¢
- âœ… `examples/node-client.js` - Node.js å®¢æˆ·ç«¯ç¤ºä¾‹

### é…ç½®æ¨¡æ¿

```javascript
// ç”Ÿäº§ç¯å¢ƒé…ç½®ç¤ºä¾‹
export const productionConfig = {
  scrapeMode: 'multiple_pages',
  imageMode: 'originals_only',
  targetUrls: process.env.TARGET_URLS?.split(',') || [],
  outputDirectory: process.env.OUTPUT_DIR || './download',
  maxRetries: 3,
  concurrentDownloads: 10,
  analysis: {
    mode: 'twoPhase',
    cleanupTempOnComplete: true
  }
}
```

---

## ğŸ¤ è´¡çŒ®å’Œåé¦ˆ

å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ã€å»ºè®®æˆ–å‘ç°äº† bugï¼š

1. æŸ¥çœ‹ç›¸å…³æ–‡æ¡£
2. æäº¤ GitHub Issue
3. å‘èµ· Pull Request

---

## ğŸ‰ æ€»ç»“

æ­å–œï¼ä½ çš„ thumb2original é¡¹ç›®ç°åœ¨ï¼š

âœ… **æ—¢æ˜¯å¼ºå¤§çš„ CLI å·¥å…·**
âœ… **åˆæ˜¯çµæ´»çš„ API æœåŠ¡**
âœ… **æ¶æ„æ¸…æ™°ï¼Œæ˜“äºæ‰©å±•**
âœ… **æ–‡æ¡£å®Œå–„ï¼Œä¸Šæ‰‹ç®€å•**

å¼€å§‹äº«å—åŒæ¨¡å¼å¸¦æ¥çš„ä¾¿åˆ©å§ï¼ ğŸš€

---

**ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒæ–‡æ¡£æˆ–æäº¤ Issueã€‚**
